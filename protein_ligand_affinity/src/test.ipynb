{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from utils import random_split\n",
    "from dataset import MyDataset\n",
    "import torch.nn as nn\n",
    "from model import Mymodel,Mymodel2\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from metrics import*\n",
    "from torch_geometric.data import Batch\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import os\n",
    "\n",
    "from GIGN import GIGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed is found...\n",
      "Processed is found...\n",
      "Processed is found...\n",
      "Processed is found...\n",
      "Processed is found...\n",
      "Processed is found...\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "cutoff = 5\n",
    "dataset = 'general'\n",
    "\n",
    "train_pkl = torch.load('./protein_ligand_affinity/data/graph/train_{}A.pkl'.format(cutoff))\n",
    "valid_pkl = torch.load('./protein_ligand_affinity/data/graph/valid_{}A.pkl'.format(cutoff))\n",
    "test2016_pkl = torch.load('./protein_ligand_affinity/data/graph/test_{}A.pkl'.format(cutoff))\n",
    "test2013_pkl = torch.load('./protein_ligand_affinity/data/graph/CASF2013_coreset_{}A.pkl'.format(cutoff))\n",
    "#csarhiq_pkl = torch.load('./protein_ligand_affinity/data/graph/csar_hiq_{}A.pkl'.format(cutoff))\n",
    "test2019_pkl = torch.load('./protein_ligand_affinity/data/graph/test2019_{}A.pkl'.format(cutoff))\n",
    "test2019_id30_pkl = torch.load('./protein_ligand_affinity/data/graph/test2019_id30_{}A.pkl'.format(cutoff))\n",
    "root = 'protein_ligand_affinity/data/'\n",
    "\n",
    "train_data =  MyDataset(root, dataset, train_pkl, 'train')\n",
    "valid_data =  MyDataset(root, dataset, valid_pkl, 'valid')\n",
    "test2016_data = MyDataset(root, dataset, test2016_pkl, 'test')\n",
    "test2013_data = MyDataset(root, dataset, test2013_pkl, 'casf2013')\n",
    "#csarhiq_data = MyDataset(root, dataset, csarhiq_pkl, 'csarhiq')\n",
    "test2019_data = MyDataset(root, dataset, test2019_pkl, 'test2019')\n",
    "test2019_id30_data = MyDataset(root, dataset, test2019_id30_pkl, 'test2019_id30')\n",
    "\n",
    "train_loader = DataLoader(train_data, BATCH_SIZE)\n",
    "valid_loader = DataLoader(valid_data, BATCH_SIZE)\n",
    "test2016_loader = DataLoader(test2016_data, BATCH_SIZE)\n",
    "test2013_loader = DataLoader(test2013_data, BATCH_SIZE)\n",
    "#csarhiq_loader = DataLoader(csarhiq_data, BATCH_SIZE)\n",
    "test2019_loader = DataLoader(test2019_data, BATCH_SIZE)\n",
    "test2019_id30_loader = DataLoader(test2019_id30_data, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Mymodel(atom_in_dim = 35, bond_in_dim = 6, hidden_dim = 256, rbf_num = 9, num_heads = 4, dropout = 0.1)\n",
    "#model = GIGN(35, 256)\n",
    "model = model.to(device)\n",
    "\n",
    "ckpt = 'epoch-164, valid_rmse-1.215379, valid_mae-0.924372, valid_r-0.755567, valid_sd-1.209885.pt'\n",
    "model.load_state_dict(torch.load(ckpt))\n",
    "\n",
    "def valid_and_test(model, device, loader):\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    label_list = []\n",
    "    for _, data in enumerate(loader):\n",
    "        data = data.to(device) \n",
    "        label = data.y\n",
    "        with torch.no_grad():\n",
    "            pred = model(data)\n",
    "            pred_list.append(pred.detach().cpu().numpy())\n",
    "            label_list.append(label.detach().cpu().numpy())\n",
    "        \n",
    "    y_pred = np.concatenate(pred_list, axis=0)\n",
    "    y_true = np.concatenate(label_list, axis=0) \n",
    "\n",
    "    return y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_true = valid_and_test(model, device, test2016_loader)\n",
    "rmse = RMSE(y_true, y_pred)\n",
    "mae = MAE(y_true, y_pred)\n",
    "r = PR(y_true, y_pred)\n",
    "sd = SD(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2449945 0.98465973 0.8237182799916165 1.232818639782146\n"
     ]
    }
   ],
   "source": [
    "print(rmse, mae, r, sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mse = [1.4403255, 1.4857787, 1.4172947]\n",
    "mae = [1.1338453, 1.1845926, 1.1329943]\n",
    "r = [0.4678340, 0.4362635, 0.4892939]\n",
    "sd = [1.3715729, 1.3964069, 1.3534201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4477996333333334 0.028453606283601773\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(mse), np.std(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1504774 0.02412559088782422\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(mae), np.std(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46446380000000004 0.02178033542854654\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(r), np.std(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3737999666666667 0.01761980160715651\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(sd), np.std(sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# 假设 y_true 和 y_pred 已经定义\n",
    "# 例如:\n",
    "# y_true = np.random.normal(0, 1, 100)\n",
    "# y_pred = np.random.normal(0, 1, 100)\n",
    "\n",
    "# 使用Seaborn绘制散点图和边缘直方图\n",
    "g = sns.jointplot(x=y_true, y=y_pred, kind=\"scatter\", marginal_kws=dict(bins=25, fill=True, stat='density', color='#FEA55F'), color = '#FFCB5F')\n",
    "\n",
    "# 计算真实值和预测值的均值和标准差\n",
    "mu_true, sigma_true = np.mean(y_true), np.std(y_true)\n",
    "mu_pred, sigma_pred = np.mean(y_pred), np.std(y_pred)\n",
    "\n",
    "# 生成正态分布的概率密度函数值\n",
    "x_true = np.linspace(min(y_true), max(y_true), 1000)\n",
    "y_true_curve = norm.pdf(x_true, mu_true, sigma_true)\n",
    "\n",
    "x_pred = np.linspace(min(y_pred), max(y_pred), 1000)\n",
    "y_pred_curve = norm.pdf(x_pred, mu_pred, sigma_pred)\n",
    "\n",
    "# 绘制正态分布曲线\n",
    "g.ax_marg_x.plot(x_true, y_true_curve, '#FEA55F')\n",
    "g.ax_marg_y.plot(y_pred_curve, x_pred, '#FEA55F') \n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = linregress(y_true, y_pred)\n",
    "x_fit = np.linspace(min(y_true), max(y_true), 100)\n",
    "y_fit = slope * x_fit + intercept\n",
    "\n",
    "# 在散点图上添加拟合线\n",
    "g.ax_joint.plot(x_fit, y_fit, '#FEA55F', linewidth=2)\n",
    "\n",
    "g.ax_joint.text(x=0.05, y=0.95, s=\"CASF2013\\nRMSE=1.365\", \n",
    "                fontdict={'family': 'Times New Roman', 'size': 16}, ha='left', va='top', transform=g.ax_joint.transAxes)\n",
    "\n",
    "for label in (g.ax_joint.get_xticklabels() + g.ax_joint.get_yticklabels()):\n",
    "    label.set_fontname('Times New Roman')\n",
    "    label.set_fontsize(16)\n",
    "\n",
    "plt.savefig('plot2013.png', dpi=600) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 绘制拟合曲线\n",
    "model = LinearRegression()\n",
    "model.fit(y_true.reshape(-1, 1), y_pred)\n",
    "x_fit = np.linspace(1, 14, 100).reshape(-1, 1)\n",
    "y_fit = model.predict(x_fit)\n",
    "\n",
    "plt.figure(dpi=600)  # 设置DPI为600\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "# 绘制相关图\n",
    "plt.figure(figsize=(8, 8))  # 设置图形的大小\n",
    "\n",
    "plt.scatter(y_true, y_pred, c = '#FF6347', marker='v', zorder = 2, s= 80, edgecolor = '#FF6347',linewidths = 1)  # 绘制散点图   #FAA460, \n",
    "plt.plot(x_fit, y_fit, color = '#FF6347', linewidth=3.5)\n",
    "\n",
    "plt.xlabel('Label', fontname='Times New Roman', fontsize = 28, fontweight='bold')  # 设置x轴标签\n",
    "plt.ylabel('Prediction', fontname='Times New Roman', fontsize = 28, fontweight='bold')  # 设置y轴标签\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "plt.xticks(np.arange(0, 17.1, 2), fontsize=28)\n",
    "plt.yticks(np.arange(0, 17.1, 2), fontsize=28)\n",
    "\n",
    "#plt.xlim(0, 16)  # 设置 x 轴的区间\n",
    "#plt.ylim(0, 16) \n",
    "plt.grid(True, linestyle = '--')  # 显示网格线\n",
    " \n",
    "# 设置Y轴的刻度显示格式\n",
    "plt.text(0.05, 0.92, 'valid', transform=plt.gca().transAxes, fontname='Times New Roman',fontsize=28, fontweight='bold',color='k')\n",
    "plt.text(0.053, 0.85, 'RMSE = 1.171', transform=plt.gca().transAxes, fontname='Times New Roman',fontsize=18, fontweight='bold',color='k')\n",
    "plt.text(0.053, 0.79, 'R = 0.776', transform=plt.gca().transAxes, fontname='Times New Roman',fontsize=18, fontweight='bold',color='k')\n",
    "plt.text(0.9, 0.92, '(A)', transform=plt.gca().transAxes, fontname='Times New Roman',fontsize=32, fontweight='bold',color='k')\n",
    "\n",
    "plt.savefig('valid.png', dpi=600)\n",
    "plt.show()  # 显示图形，  基于这段代码修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "random_index = list(range(0, 11904))\n",
    "random.shuffle(random_index)\n",
    "index_list = random_index[:256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class UseHook():\n",
    "    def __init__(self, model, module):\n",
    "        self.model = model\n",
    "        module.register_forward_hook(self.save_hook)\n",
    "\n",
    "    def save_hook(self, md, fin, fout):\n",
    "        self.target_feat = fout\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        self.model.eval()\n",
    "        output = self.model(data)\n",
    "        return self.target_feat[0].detach().cpu().numpy()\n",
    "\n",
    "hook = UseHook(model, model.predict_layer.mlp[0])\n",
    "\n",
    "feats_in_hook  = []\n",
    "affinity = []\n",
    "\n",
    "#随机选择256个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in index_list:\n",
    "    data = Batch.from_data_list([train_data[idx]])\n",
    "    label = data.y.numpy()\n",
    "\n",
    "    data = data.to(device)\n",
    "    feats = hook(data)\n",
    "\n",
    "    feats_in_hook.append(hook(data))\n",
    "    affinity.append(label)\n",
    "\n",
    "feats_in_hook = np.stack(feats_in_hook, axis = 0).reshape(256, 512)\n",
    "affinity = np.array(affinity).reshape(-1)\n",
    "\n",
    "x_min, x_max = np.min(affinity), np.max(affinity)\n",
    "affinity = (affinity - x_min) / (x_max - x_min)\n",
    "affinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设你有一个包含高维向量的 NumPy 数组，每一行是一个向量\n",
    "# 这里假设 data 是一个形状为 (n_samples, 256) 的数组\n",
    "# 你需要将 data 替换为你自己的数据\n",
    "\n",
    "# 创建一个 t-SNE 模型并将数据降维到 2 维\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, perplexity = 30, early_exaggeration = 20, init = 'pca', random_state = 42)\n",
    "low_dimension = tsne.fit_transform(feats_in_hook)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(low_dimension[:, 0], low_dimension[:, 1], marker='o', s = 70, c = affinity, cmap='coolwarm', vmin=0, vmax=1)\n",
    "\n",
    "# 显示坐标轴边框\n",
    "plt.gca().xaxis.set_ticks_position('none')  # x轴的刻度线位置设置为'none'\n",
    "plt.gca().yaxis.set_ticks_position('none')  # y轴的刻度线位置设置为'none'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "t_rmse, t_mae, t_r, t_sd = valid_and_test(model, device, test2016_loader)\n",
    "        \n",
    "print(\"doing final testing!\")\n",
    "print(\"test_rmse: {:.6f}, test_mae: {:.6f}, test_r: {:.6f}, test_sd: {:.6f}\".format(t_rmse, t_mae, t_r, t_sd))\n",
    "    \n",
    "t2013_rmse, t2013_mae, t2013_r, t2013_sd = valid_and_test(model, device, test2013_loader)\n",
    "print(\"test2013_rmse: {:.6f}, test_mae: {:.6f}, test_r: {:.6f}, test_sd: {:.6f}\".format(t2013_rmse, t2013_mae,\n",
    "                                                                                             t2013_r, t2013_sd))\n",
    "'''                                    \n",
    "def valid_and_test(model, device, valid_loader):\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    label_list = []\n",
    "    for _, data in enumerate(valid_loader):\n",
    "        data = data.to(device) \n",
    "        label = data.y\n",
    "        with torch.no_grad():\n",
    "            pred = model(data)\n",
    "\n",
    "    '''\n",
    "            pred_list.append(pred.detach().cpu().numpy())\n",
    "            label_list.append(label.detach().cpu().numpy())\n",
    "        \n",
    "    y_pred = np.concatenate(pred_list, axis=0)\n",
    "    y_true = np.concatenate(label_list, axis=0) \n",
    "\n",
    "    return y_pred, y_true\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    rmse = RMSE(y_true, y_pred)\n",
    "    mae = MAE(y_true, y_pred)\n",
    "    r = PR(y_true, y_pred)\n",
    "\n",
    "    sd = SD(y_true,y_pred)\n",
    "\n",
    "    return rmse, mae, r, sd\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7fb233b44bbf5f3e115c87567f38936f5c82fa4a828bd1ac69772ebe10a8b2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
